{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for one light curve, 3 obs in two fitlters; > 5sigma;\n",
    "\n",
    "all combination of time gaps, observations;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one light curve, multiple combinations\n",
    "\n",
    "f1 f2 f3\n",
    "\n",
    "total number of events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lsst.sims.maf.db as db\n",
    "from lsst.sims.maf.utils import m52snr\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.plots as plots\n",
    "\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "from lsst.sims.utils import equatorialFromGalactic, hpid2RaDec, _healbin, healbin\n",
    "from lsst.utils import getPackageDir\n",
    "#from mafContrib import KN_lc, KNePopMetric, generateKNPopSlicer\n",
    "import healpy as hp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.sims.photUtils import Sed, BandpassDict\n",
    "\n",
    "\n",
    "class Dust_values(object):\n",
    "    \"\"\"Calculate extinction values\n",
    "    Parameters\n",
    "    ----------\n",
    "    R_v : float (3.1)\n",
    "        Extinction law parameter (3.1).\n",
    "    bandpassDict : dict (None)\n",
    "        A dict with keys of filtername and values of rubin_sim.photUtils.Bandpass objects. Default\n",
    "        of None will load the standard ugrizy bandpasses.\n",
    "    ref_ev : float (1.)\n",
    "        The reference E(B-V) value to use. Things in MAF assume 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, R_v=3.1, bandpassDict=None, ref_ebv=1.):\n",
    "        # Calculate dust extinction values\n",
    "        self.Ax1 = {}\n",
    "        if bandpassDict is None:\n",
    "            bandpassDict = BandpassDict.loadTotalBandpassesFromFiles(['u', 'g', 'r', 'i', 'z', 'y'])\n",
    "\n",
    "        for filtername in bandpassDict:\n",
    "            wavelen_min = bandpassDict[filtername].wavelen.min()\n",
    "            wavelen_max = bandpassDict[filtername].wavelen.max()\n",
    "            testsed = Sed()\n",
    "            testsed.setFlatSED(wavelen_min=wavelen_min, wavelen_max=wavelen_max, wavelen_step=1.0)\n",
    "            self.ref_ebv = ref_ebv\n",
    "            # Calculate non-dust-extincted magnitude\n",
    "            flatmag = testsed.calcMag(bandpassDict[filtername])\n",
    "            # Add dust\n",
    "            a, b = testsed.setupCCM_ab()\n",
    "            testsed.addDust(a, b, ebv=self.ref_ebv, R_v=R_v)\n",
    "            # Calculate difference due to dust when EBV=1.0 (m_dust = m_nodust - Ax, Ax > 0)\n",
    "            self.Ax1[filtername] = testsed.calcMag(bandpassDict[filtername]) - flatmag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "#from lsst.sims.utils import uniformSphere\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "#from lsst.sims.photUtils import Dust_values\n",
    "\n",
    "\n",
    "__all__ = ['KN_lc', 'KNePopMetric', 'generateKNPopSlicer']\n",
    "\n",
    "\n",
    "def uniformSphere(npoints, seed=42):\n",
    "    \"\"\"\n",
    "    Just make RA, dec points on a sphere\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    u = np.random.uniform(size=npoints)\n",
    "    v = np.random.uniform(size=npoints)\n",
    "\n",
    "    ra = 2.*np.pi * u\n",
    "    dec = np.arccos(2.*v - 1.)\n",
    "    # astro convention of -90 to 90\n",
    "    dec -= np.pi/2.\n",
    "    return np.degrees(ra), np.degrees(dec)\n",
    "\n",
    "\n",
    "class KN_lc(object):\n",
    "    \"\"\"\n",
    "    Read in some KNe lightcurves\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_list : list of str (None)\n",
    "        List of file paths to load. If None, loads up all the files from data/bns/\n",
    "    \"\"\"\n",
    "    def __init__(self, file_list=None):\n",
    "        if file_list is None:\n",
    "            sims_maf_contrib_dir = os.getenv(\"SIMS_MAF_CONTRIB_DIR\")\n",
    "            # Get files, model grid developed by M. Bulla\n",
    "            file_list = glob.glob(os.path.join(sims_maf_contrib_dir, 'data/bns/*.dat'))\n",
    "\n",
    "        filts = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "        magidxs = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "        # Let's organize the data in to a list of dicts for easy lookup\n",
    "        self.data = []\n",
    "        for filename in file_list:\n",
    "            mag_ds = np.loadtxt(filename)\n",
    "            t = mag_ds[:, 0]\n",
    "            new_dict = {}\n",
    "            for ii, (filt, magidx) in enumerate(zip(filts, magidxs)):\n",
    "                new_dict[filt] = {'ph': t, 'mag': mag_ds[:, magidx]}\n",
    "            self.data.append(new_dict)\n",
    "\n",
    "    def interp(self, t, filtername, lc_indx=0):\n",
    "        \"\"\"\n",
    "        t : array of floats\n",
    "            The times to interpolate the light curve to.\n",
    "        filtername : str\n",
    "            The filter. one of ugrizy\n",
    "        lc_index : int (0)\n",
    "            Which file to use.\n",
    "        \"\"\"\n",
    "\n",
    "        result = np.interp(t, self.data[lc_indx][filtername]['ph'],\n",
    "                           self.data[lc_indx][filtername]['mag'],\n",
    "                           left=99, right=99)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radec2gal(ra, dec):\n",
    "    '''convert from ra/dec to galactic l/b'''\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    from astropy import units as u\n",
    "    c = SkyCoord(ra=ra, dec=dec, \n",
    "                 unit=(u.degree, u.degree))\n",
    "    \n",
    "    l = c.galactic.l.degree\n",
    "    b = c.galactic.b.degree\n",
    "    return l, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateKNPopSlicer(t_start=1, t_end=3652, n_events=10000, \n",
    "                        skyregion='all', \n",
    "                        seed=42, n_files=100, d_min=10, d_max=300):\n",
    "    \"\"\" Generate a population of KNe events, and put the info about them\n",
    "    into a UserPointSlicer object\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_start : float (1)\n",
    "        The night to start kilonova events on (days)\n",
    "    t_end : float (3652)\n",
    "        The final night of kilonova events\n",
    "    n_events : int (10000)\n",
    "        The number of kilonova events to generate\n",
    "    seed : float\n",
    "        The seed passed to np.random\n",
    "    n_files : int (7)\n",
    "        The number of different kilonova lightcurves to use\n",
    "    d_min : float or int (10)\n",
    "        Minimum luminosity distance (Mpc)\n",
    "    d_max : float or int (300)\n",
    "        Maximum luminosity distance (Mpc)\n",
    "    \"\"\"\n",
    "\n",
    "    def rndm(a, b, g, size=1):\n",
    "        \"\"\"Power-law gen for pdf(x)\\propto x^{g-1} for a<=x<=b\"\"\"\n",
    "        r = np.random.random(size=size)\n",
    "        ag, bg = a**g, b**g\n",
    "        return (ag + (bg - ag)*r)**(1./g)\n",
    "\n",
    "    ra, dec = uniformSphere(n_events, seed=seed)\n",
    "    \n",
    "    ###Convert ra, dec to gl, gb\n",
    "    gl, gb = radec2gal(ra, dec)\n",
    "   \n",
    "    ###Determine if the object is in the Galaxy plane\n",
    "    \n",
    "    if skyregion is 'glactic':#keep the glactic events\n",
    "        ra = ra[np.abs(gb)<20]\n",
    "        dec= dec[np.abs(gb)<20]\n",
    "    elif skyregion is 'extragalaxtic': #keep the extragalactic events.\n",
    "        ra = ra[np.abs(gb)>20]\n",
    "        dec= dec[np.abs(gb)>20]\n",
    "    \n",
    "    n_events = len(ra) \n",
    "    #len(ra)>n_events\n",
    "    #ra = ra[:n_events]\n",
    "    #dec = dec[]\n",
    "    \n",
    "    peak_times = np.random.uniform(low=t_start, high=t_end, size=n_events)\n",
    "    file_indx = np.floor(np.random.uniform(low=0, high=n_files,\n",
    "                                           size=n_events)).astype(int)\n",
    "\n",
    "    # Define the distance\n",
    "    distance = rndm(d_min, d_max, 4, size=n_events)\n",
    "\n",
    "    # Set up the slicer to evaluate the catalog we just made\n",
    "    slicer = slicers.UserPointsSlicer(ra, dec, latLonDeg=True, badval=0)\n",
    "    # Add any additional information about each object to the slicer\n",
    "    slicer.slicePoints['peak_time'] = peak_times\n",
    "    slicer.slicePoints['file_indx'] = file_indx\n",
    "    slicer.slicePoints['distance'] = distance\n",
    "    \n",
    "    return slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "class KNePopMetric(metrics.BaseMetric):\n",
    "    def __init__(self, metricName='KNePopMetric', mjdCol='observationStartMJD',\n",
    "                 m5Col='fiveSigmaDepth', filterCol='filter', nightCol='night',\n",
    "                 ptsNeeded=2, file_list=None, mjd0=59853.5, outputLc=False,\n",
    "                 skyregion='all',\n",
    "                 filePathGalactic='/home/idies/workspace/Storage/lianmign/persistent/DataCube/TotalCubeNorm_1000Obj.pkl',\n",
    "                 filePathExtragalactic='/home/idies/workspace/Storage/lianmign/persistent/DataCube/TotalCubeNorm_1000Obj.pkl',\n",
    "                 **kwargs):\n",
    "        maps = ['DustMap']\n",
    "        self.mjdCol = mjdCol\n",
    "        self.m5Col = m5Col\n",
    "        self.filterCol = filterCol\n",
    "        self.nightCol = nightCol\n",
    "        self.ptsNeeded = ptsNeeded # detection points threshold\n",
    "        # Boolean variable, if True the light curve will be exported\n",
    "        self.outputLc = outputLc\n",
    "        \n",
    "        self.filePath = None\n",
    "        if skyregion is 'galactic':\n",
    "            self.filePath = filePathGalactic\n",
    "        elif skyregion is 'extragalactic':\n",
    "            self.filePath = filePathExtragalactic           \n",
    "        \n",
    "        if skyregion is not 'all':\n",
    "            self.InfoDict = None\n",
    "            self.HashTable = None\n",
    "            with open(self.filePath, 'rb') as f:\n",
    "                self.InfoDict = pickle.load( f )\n",
    "                self.HashTable = pickle.load( f )          \n",
    "        \n",
    "        # read in file as light curve object;\n",
    "        self.lightcurves = KN_lc(file_list=file_list)\n",
    "        self.mjd0 = mjd0\n",
    "\n",
    "        dust_properties = Dust_values()\n",
    "        self.Ax1 = dust_properties.Ax1\n",
    "\n",
    "        cols = [self.mjdCol, self.m5Col, self.filterCol, self.nightCol]\n",
    "        super(KNePopMetric, self).__init__(col=cols, units='Detected, 0 or 1',\n",
    "                                           metricName=metricName, maps=maps,\n",
    "                                           **kwargs)\n",
    "\n",
    "    def _multi_detect(self, around_peak):\n",
    "        \"\"\"\n",
    "        Simple detection criteria: detect at least a certain number of times\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        # Detected data points\n",
    "        if np.size(around_peak) < self.ptsNeeded:\n",
    "            return 0\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def _presto_color_detect(self, around_peak, filters):\n",
    "        \"\"\"\n",
    "        detection criteria of presto cadence: at least three detections at two filters;\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        \n",
    "        if np.size(around_peak)<3:\n",
    "            result = 0\n",
    "        \n",
    "        flts, flts_count = np.unique(filters, return_counts=True,)\n",
    "        if np.size(flts) < 2:\n",
    "            result = 0\n",
    "        elif np.max(flts_count) < 2:\n",
    "            # if no filters have visits larger than 2, set detection false\n",
    "            result = 0\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def _enquiry(self, HashTable, InfoDict, Band1, Band2, dT1, dT2, dMag, Color):\n",
    "        \"\"\"\n",
    "        Return the value in the probability cube provided the coordinates \n",
    "        in the Presto-Color phase space of an observation triplet.\n",
    "        \"\"\"\n",
    "    \n",
    "#         if abs(dT1) > abs(dT1-dT2):\n",
    "#             dT1, dT2 = dT1-dT2, -dT2\n",
    "\n",
    "        if not ( InfoDict['BinMag'][0]<=dMag<InfoDict['BinMag'][-1] and InfoDict['BinColor'][0]<=Color<InfoDict['BinColor'][-1] ):\n",
    "            return 0\n",
    "\n",
    "        Ind1 = InfoDict['BandPairs'].index(Band1+Band2)\n",
    "\n",
    "        dT1grid = InfoDict['dT1s'][ abs( dT1 - InfoDict['dT1s'] ).argmin() ]\n",
    "        dT2grid = InfoDict['dT2s'][ abs( dT2 - InfoDict['dT2s'] ).argmin() ]\n",
    "        TimePairGrid = [ InfoDict['dT1s'][ abs( dT1 - InfoDict['dT1s'] ).argmin() ], InfoDict['dT2s'][ abs( dT2 - InfoDict['dT2s'] ).argmin() ] ]\n",
    "\n",
    "        Ind2 = np.where( (InfoDict['TimePairs'] == TimePairGrid ).all(axis=1) )[0][0]        \n",
    "        Ind3 = np.where( dMag >= InfoDict['BinMag'] )[0][-1]        \n",
    "        Ind4 = np.where( Color >= InfoDict['BinColor'] )[0][-1]\n",
    "        \n",
    "        return HashTable[Ind1, Ind2, Ind3, Ind4]\n",
    "    \n",
    "    def _getScore(self, result, HashTable, InfoDict, scoreType='S', thr=0.003):\n",
    "        \"\"\"\n",
    "        Get the score of a strategy from the Presto-Color perspective.\n",
    "        \"\"\"\n",
    "        \n",
    "        TimeLim1 = 8.125/24 # 8 h 7.5 min\n",
    "        TimeLim2 = 32.25/24 # 32 h 15 min\n",
    "        \n",
    "        Detects = result[result.mag<result.maglim]        \n",
    "        \n",
    "        Ts = Detects.t.values  #Times for valid detections\n",
    "        dTs = Ts.reshape(1,len(Ts)) - Ts.reshape(len(Ts),1) #Find out the differences between each pair\n",
    "\n",
    "        dTindex0, dTindex1 = np.where( abs(dTs)<TimeLim2 ) #The time differences should be within 32 hours (2 nights)\n",
    "        \n",
    "        phaseSpaceCoords = []\n",
    "        \n",
    "        #loop through the rows of the matrix of valid time differences\n",
    "        for ii in range(dTs.shape[0]):\n",
    "            \n",
    "            groupsOfThree = np.array( [ [ii] + list(jj) for jj in list(combinations( dTindex1[ (dTindex0==ii) * (dTindex1>ii) ], 2)) ] )\n",
    "\n",
    "            for indices in groupsOfThree:\n",
    "\n",
    "                Bands = Detects[\"filter\"][indices].values\n",
    "                if len(np.unique(Bands)) != 2:\n",
    "                    continue\n",
    "\n",
    "                #The band appears once will be Band2  \n",
    "                occurence = np.array([ np.count_nonzero(ii==Bands) for ii in Bands ]) \n",
    "\n",
    "                index2 = indices[occurence==1][0] #The index of observation in Band2\n",
    "                index11 = indices[occurence==2][0] #The index of the first observation in Band1\n",
    "                index12 = indices[occurence==2][1] #The index of the second observation in Band1\n",
    "\n",
    "                if abs(dTs[ index12, index2 ])<abs(dTs[ index11, index2 ]) and abs(dTs[ index12, index2 ])<TimeLim1:\n",
    "                    index11, index12 = index12, index11\n",
    "                elif abs(dTs[ index11, index2 ])>TimeLim1:\n",
    "                    continue\n",
    "\n",
    "                dT1 = dTs[index11, index2]        \n",
    "                dT2 = dTs[index11, index12]\n",
    "\n",
    "                Band1 = Bands[ occurence==2 ][0]\n",
    "                Band2 = Bands[ occurence==1 ][0]\n",
    "\n",
    "                dMag = (Detects.mag[index11] - Detects.mag[index12]) * np.sign(dT2)\n",
    "                Color = Detects.mag[index11] - Detects.mag[index2]\n",
    "\n",
    "                phaseSpaceCoords.append( [Band1, Band2, dT1, dT2, dMag, Color] )        \n",
    "                    \n",
    "        score = 0\n",
    "        \n",
    "        if scoreType == 'S':\n",
    "            for phaseSpaceCoord in phaseSpaceCoords:\n",
    "                rate = _enquiry(HashTable, InfoDict, *phaseSpaceCoord)\n",
    "                \n",
    "                if rate < thr:\n",
    "                    score += 1\n",
    "                    \n",
    "                return score / len(phaseSpaceCoords)\n",
    "            \n",
    "        elif scoreType == 'P':\n",
    "            for phaseSpaceCoord in phaseSpaceCoords:\n",
    "                rate = self._enquiry(HashTable, InfoDict, *phaseSpaceCoord)\n",
    "                \n",
    "                score += ( 1-rate )\n",
    "                \n",
    "                return score / len(phaseSpaceCoords)\n",
    "            \n",
    "\n",
    "    def _ztfrest_simple(self, around_peak, mags, t, filters, min_dt=0.125,\n",
    "                        min_fade=0.3, max_rise=-1., selectRed=False):\n",
    "        \"\"\"\n",
    "        Selection criteria based on rise or decay rate; simplified version of\n",
    "        the methods employed by the ZTFReST project\n",
    "        (Andreoni & Coughlin et al., 2021)\n",
    "        Parameters\n",
    "        ----------\n",
    "        around_peak : array\n",
    "            indexes corresponding to 5sigma detections\n",
    "        mags : array\n",
    "            magnitudes obtained interpolating models on the dataSlice\n",
    "        t : array\n",
    "            relative times\n",
    "        filters : array\n",
    "            filters in which detections happened\n",
    "        min_dt : float\n",
    "            minimum time gap between first and last detection in a given band\n",
    "        min_fade : float\n",
    "            fade rate threshold (positive, mag/day)\n",
    "        max_rise : float\n",
    "            rise rate threshold (negative, mag/day)\n",
    "        selectRed : bool\n",
    "            if True, only red 'izy' filters will be considered\n",
    "        Examples\n",
    "        ----------\n",
    "        A transient:\n",
    "            rising by 0.74 mag/day will pass a threshold max_rise=-0.5\n",
    "            rising by 0.74 mag/day will not pass a threshold max_rise=-1.0\n",
    "            fading by 0.6 mag/day will pass a threshold min_fade=0.3\n",
    "            fading by 0.2 mag/day will not pass a threshold min_fade=0.3\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "\n",
    "        # Quick check on the number of detected points\n",
    "        if np.size(around_peak) < self.ptsNeeded:\n",
    "            return 0\n",
    "        # Quick check on the time gap between first and last detection\n",
    "        elif np.max(t[around_peak]) - np.min(t[around_peak]) < min_dt:\n",
    "            return 0\n",
    "        else:\n",
    "            evol_rate = []\n",
    "            fil = []\n",
    "            # Check time gaps and rise or fade rate for each band\n",
    "            for f in set(filters):\n",
    "                if selectRed is True and not (f in 'izy'):\n",
    "                    continue\n",
    "                times_f = t[around_peak][np.where(filters == f)[0]]\n",
    "                mags_f = mags[around_peak][np.where(filters == f)[0]]\n",
    "                dt_f = np.max(times_f) - np.min(times_f)\n",
    "                # Calculate the evolution rate, if the time gap condition is met\n",
    "                if dt_f > min_dt:\n",
    "                    evol_rate_f = (np.max(mags_f) - np.min(mags_f)) / (times_f[np.where(mags_f == np.max(mags_f))[0]][0] - times_f[np.where(mags_f == np.min(mags_f))[0]][0])\n",
    "                    evol_rate.append(evol_rate_f)\n",
    "                else:\n",
    "                    evol_rate.append(0)\n",
    "                fil.append(f)\n",
    "            if len(evol_rate) == 0:\n",
    "                return 0\n",
    "            # Check if the conditions on the evolution rate are met\n",
    "            if np.max(evol_rate) < min_fade and np.min(evol_rate) > max_rise:\n",
    "                return 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _multi_color_detect(self, filters):\n",
    "        \"\"\"\n",
    "        Color-based simple detection criteria: detect at least twice,\n",
    "        with at least two filters\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        # detected in at least two filters\n",
    "        if np.size(np.unique(filters)) < 2:\n",
    "            return 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _red_color_detect(self, filters, min_det=4):\n",
    "        \"\"\"\n",
    "        Detected at least min_det times in either izy colors\n",
    "        Parameters\n",
    "        ----------\n",
    "        filters : array\n",
    "            filters in which detections happened\n",
    "        min_det : float or int\n",
    "            minimum number of detections required in izy bands\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        # Number of detected points in izy bands\n",
    "        n_red_det = np.size(np.where(filters == 'i')[0]) + np.size(np.where(filters == 'z')[0]) + np.size(np.where(filters == 'y')[0])\n",
    "        # Condition\n",
    "        if n_red_det < min_det:\n",
    "            return 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _blue_color_detect(self, filters, min_det=4):\n",
    "        \"\"\"\n",
    "        Detected at least min_det times in either ugr colors\n",
    "        Parameters\n",
    "        ----------\n",
    "        filters : array\n",
    "            filters in which detections happened\n",
    "        min_det : float or int\n",
    "            minimum number of detections required in ugr bands\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        # Number of detected points in ugr bands\n",
    "        n_blue_det = np.size(np.where(filters == 'u')[0]) + np.size(np.where(filters == 'g')[0]) + np.size(np.where(filters == 'r')[0])\n",
    "        # Condition\n",
    "        if n_blue_det < min_det:\n",
    "            return 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        dataSlice.sort(order=self.mjdCol)\n",
    "        result = {}\n",
    "        t = dataSlice[self.mjdCol] - self.mjd0 - slicePoint['peak_time']\n",
    "        mags = np.zeros(t.size, dtype=float)\n",
    "        \n",
    "        for filtername in np.unique(dataSlice[self.filterCol]):\n",
    "            infilt = np.where(dataSlice[self.filterCol] == filtername)\n",
    "            mags[infilt] = self.lightcurves.interp(t[infilt], filtername,\n",
    "                                                   lc_indx=slicePoint['file_indx'])\n",
    "            # Apply dust extinction on the light curve\n",
    "            A_x = self.Ax1[filtername] * slicePoint['ebv']\n",
    "            mags[infilt] += A_x\n",
    "\n",
    "            distmod = 5*np.log10(slicePoint['distance']*1e6) - 5.0\n",
    "            mags[infilt] += distmod\n",
    "\n",
    "        # Find the detected points\n",
    "        around_peak = np.where((t > 0) & (t < 30) & (mags < dataSlice[self.m5Col]))[0]        \n",
    "        # Filters in which the detections happened\n",
    "        filters = dataSlice[self.filterCol][around_peak]\n",
    "        \n",
    "        #result['multi_detect'] = self._multi_detect(around_peak)\n",
    "        #result['ztfrest_simple'] = self._ztfrest_simple(around_peak, mags, t,\n",
    "        #                                                filters,\n",
    "        #                                                selectRed=False)\n",
    "        #result['ztfrest_simple_red'] = self._ztfrest_simple(around_peak, mags,\n",
    "        #                                                    t, filters,\n",
    "        #                                                    selectRed=True)\n",
    "        #result['multi_color_detect'] = self._multi_color_detect(filters)\n",
    "        #result['red_color_detect'] = self._red_color_detect(filters)\n",
    "        #result['blue_color_detect'] = self._blue_color_detect(filters)\n",
    "        \n",
    "        # presto color \n",
    "        result['presto_color_detect'] = self._presto_color_detect(around_peak, filters)\n",
    "                    \n",
    "        result['score'] = self._getScore()\n",
    "\n",
    "\n",
    "        # Export the light curve\n",
    "        if self.outputLc is True:\n",
    "            # mags[np.where(mags > 50)[0]] = 99.\n",
    "            #result['lc'] = [dataSlice[self.mjdCol], mags,\n",
    "            #                dataSlice[self.m5Col], dataSlice[self.filterCol]]\n",
    "            \n",
    "            idx = np.where(mags < 50)[0]\n",
    "            \n",
    "            result['lc'] = {'t': dataSlice[self.mjdCol][idx], \n",
    "                            'mag': mags[idx],\n",
    "                            'maglim': dataSlice[self.m5Col][idx], \n",
    "                            'filter': dataSlice[self.filterCol][idx] }\n",
    "            \n",
    "            result['slicePoint'] = slicePoint\n",
    "            \n",
    "            # mag: interpolated mag at filter\n",
    "            # maglim: observtion fiveSigmaDepth\n",
    "            \n",
    "        return result\n",
    "\n",
    "    #def reduce_multi_detect(self, metric):\n",
    "    #    return metric['multi_detect']\n",
    "\n",
    "    #def reduce_ztfrest_simple(self, metric):\n",
    "    #    return metric['ztfrest_simple']\n",
    "\n",
    "    #def reduce_ztfrest_simple_red(self, metric):\n",
    "    #    return metric['ztfrest_simple_red']\n",
    "\n",
    "    #def reduce_multi_color_detect(self, metric):\n",
    "    #    return metric['multi_color_detect']\n",
    "\n",
    "    #def reduce_red_color_detect(self, metric):\n",
    "    #    return metric['red_color_detect']\n",
    "\n",
    "    #def reduce_blue_color_detect(self, metric):\n",
    "    #    return metric['blue_color_detect']\n",
    "    \n",
    "    def reduce_presto_color_detect(self, metric):\n",
    "        return metric['presto_color_detect']\n",
    "    \n",
    "    def reduce_getScore(self, metric):\n",
    "        return metric['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc(t_obs, file_list, slicePoint, mjd0=59853.5):\n",
    "    \"\"\"return a light curve in all filters\n",
    "    slicePoint: dict, peak_time, file_indx, ebv, distance\n",
    "    \"\"\"\n",
    "            \n",
    "    # read in file as light curve object;\n",
    "    lightcurves = KN_lc(file_list=file_list)\n",
    "    #self.mjd0 = mjd0\n",
    "\n",
    "    dust_properties = Dust_values()\n",
    "    Ax1 = dust_properties.Ax1\n",
    "    \n",
    "    filts = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "    \n",
    "    t_ph = t_obs - mjd0 - slicePoint['peak_time']\n",
    "    lc_dic = {'t_obs':t_obs, 't_ph':t_ph,}\n",
    "\n",
    "    for filtername in filts:\n",
    "        #infilt = np.where(dataSlice[self.filterCol] == filtername)\n",
    "        mags = lightcurves.interp(t_ph, filtername,\n",
    "                                               lc_indx=slicePoint['file_indx'])\n",
    "        # Apply dust extinction on the light curve\n",
    "        A_x = Ax1[filtername] * slicePoint['ebv']\n",
    "        mags += A_x\n",
    "\n",
    "        distmod = 5*np.log10(slicePoint['distance']*1e6) - 5.0\n",
    "        mags += distmod\n",
    "        \n",
    "        lc_dic[filtername] = mags\n",
    "        \n",
    "    \n",
    "    return lc_dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run knemetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load opsim database\n",
    "dbpath_v15 = \"/home/idies/workspace/lsst_cadence/FBS_1.5/\"  # path to all opsim databases\n",
    "\n",
    "dbpath_v17 = \"/home/idies/workspace/lsst_cadence/FBS_1.7/\"\n",
    "\n",
    "dbpath_v171 = \"/home/idies/workspace/lsst_cadence/FBS_1.7.1/\"\n",
    "\n",
    "\n",
    "# output directory\n",
    "#dataRawDir = '/home/idies/workspace/Temporary/lixl/scratch/outDir/tGaps/'\n",
    "\n",
    "outDir = '/home/idies/workspace/Temporary/lianmign/scratch/Output'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the slicer which puts 10,000 events at random spots on the sphere\n",
    "slicer = generateKNPopSlicer(seed=42, n_events=100, n_files=308)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to maf_contrib\n",
    "sims_maf_contrib_dir = \"/home/idies/workspace/Storage/lianmign/persistent/sims_maf_contrib\"\n",
    "\n",
    "# Get files, model grid developed by M. Bulla\n",
    "file_list = glob.glob(os.path.join(sims_maf_contrib_dir, 'data/bns/*.dat'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "\n",
    "runName = 'baseline_v1.5_10yrs' \n",
    "opsdb = db.OpsimDatabase(dbpath_v15 + runName+'.db')\n",
    "\n",
    "#outDir = 'temp'\n",
    "#resultsDb = db.ResultsDb(outDir=outDir)\n",
    "\n",
    "metric = KNePopMetric(file_list=file_list, outputLc=True)\n",
    "sql = ''\n",
    "# Don't want to try and plot N individual points, \n",
    "plotDict = {'reduceFunc': np.sum, 'nside': 64, 'colorMin': 0}\n",
    "plotFuncs = [plots.HealpixSkyMap()]\n",
    "summaryMetrics=[metrics.MeanMetric(maskVal=0)]\n",
    "bundle = metricBundles.MetricBundle(metric, slicer, sql, runName=runName,\n",
    "                                    plotDict=plotDict, plotFuncs=plotFuncs,\n",
    "                                    summaryMetrics=summaryMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying database SummaryAllProps with no constraint for columns ['night', 'fiveSigmaDepth', 'fieldRA', 'fieldDec', 'observationStartMJD', 'filter'].\n",
      "Found 2224095 visits\n",
      "Running:  ['baseline_v1_5_10yrs_KNePopMetric_USER']\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "bd = metricBundles.makeBundlesDictFromList([bundle])\n",
    "bgroup = metricBundles.MetricBundleGroup(bd, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "bgroup.runAll()\n",
    "#bgroup.plotAll(closefigs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outResults = bgroup.bundleDict['baseline_v1_5_10yrs_KNePopMetric_USER'].metricValues.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presto_color_detect': 1,\n",
       " 'lc': {'t': array([59912.24533391, 59912.26114295, 59912.26799436, 59912.26840727,\n",
       "         59912.28376109, 59912.28417459, 59925.22771889, 59925.2435047 ,\n",
       "         59926.14684801, 59926.1626058 , 59928.1618407 , 59928.17759272]),\n",
       "  'mag': array([23.38326054, 22.45573206, 22.45596946, 22.45598377, 22.06141044,\n",
       "         22.0615005 , 27.9275573 , 26.66244659, 33.61257666, 30.3042942 ,\n",
       "         28.83919908, 27.39766673]),\n",
       "  'maglim': array([24.03049603, 23.70503371, 23.68179543, 23.61675769, 23.14005971,\n",
       "         22.97252525, 22.60933911, 22.18404706, 23.72003061, 23.19428348,\n",
       "         23.30374798, 22.66015113]),\n",
       "  'filter': array(['g', 'r', 'r', 'r', 'i', 'i', 'i', 'z', 'g', 'r', 'i', 'z'],\n",
       "        dtype='<U256')},\n",
       " 'slicePoint': {'sid': 44,\n",
       "  'ra': 1.62596257818143,\n",
       "  'dec': 0.44484615297881813,\n",
       "  'peak_time': 57.43210694689498,\n",
       "  'file_indx': 122,\n",
       "  'distance': 284.85060848951343,\n",
       "  'ebv': 0.548012912273407}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outResults[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0\n",
      "None 2\n",
      "None 8\n",
      "None 9\n",
      "None 10\n",
      "None 11\n",
      "None 17\n",
      "None 23\n",
      "None 24\n",
      "None 28\n",
      "None 30\n",
      "None 31\n",
      "None 32\n",
      "None 33\n",
      "None 38\n",
      "None 41\n",
      "None 43\n",
      "44\n",
      "None 45\n",
      "None 48\n",
      "None 51\n",
      "None 52\n",
      "None 55\n",
      "None 58\n",
      "None 64\n",
      "None 67\n",
      "None 68\n",
      "69\n",
      "None 71\n",
      "None 75\n",
      "None 79\n",
      "None 80\n",
      "None 81\n",
      "None 89\n",
      "None 90\n",
      "None 94\n",
      "None 95\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(outResults):\n",
    "    \n",
    "    if res!=None:\n",
    "        if res['presto_color_detect'] ==1:\n",
    "            print(i)\n",
    "    else: print('None', i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
